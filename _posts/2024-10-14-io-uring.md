---
title: io-uring notes
category: tech
tags: [linux kernel, io_uring, IO]
---

* TOC
{:toc}


io-uring notes

# **io-uring uses**

## IORING_SETUP_DEFER_TASKRUN

### motivation

- [initial patchset](https://lore.kernel.org/io-uring/20220815130911.988014-1-dylany@fb.com/)

- defer async work until user space calls io_uring_enter with the GETEVENTS flag

- [avoid to overflow CQ queue](https://lore.kernel.org/io-uring/ab2d2f5c-0e76-44a2-8a7e-6f9edcfa5a92@gmail.com/)

- improve network workload perf

### usage

- require IORING_SETUP_SINGLE_ISSUER

For DEFER_TASKRUN we require the completion task to be the same as the

submission task. This implies that there is only one submitter, so enforce that.



# **io-uring internal**

## io_kiocb double completion & link advancing in case of io-wq

1) request may be complete via task_work: 1st completetion

>
> ```
> static void io_req_complete_post(struct io_kiocb *req, unsigned issue_flags)
>     ...
> 	/*
> 	 * Handle special CQ sync cases via task_work. DEFER_TASKRUN requires
> 	 * the submitter task context, IOPOLL protects with uring_lock.
> 	 */
> 	if (ctx->task_complete || (ctx->flags & IORING_SETUP_IOPOLL)) {
> 		req->io_task_work.func = io_req_task_complete;
> 		io_req_task_work_add(req);
> 		return;
> 	}
>     ...
> ```

2) request completed via io_free_req(): final completion

> ```
> struct io_wq_work *io_wq_free_work(struct io_wq_work *work)
> {
> 	struct io_kiocb *req = container_of(work, struct io_kiocb, work);
> 	struct io_kiocb *nxt = NULL;
> 
> 	if (req_ref_put_and_test(req)) {
> 		if (req->flags & IO_REQ_LINK_FLAGS)
> 			nxt = io_req_find_next(req);
> 		io_free_req(req);
> 	}
> 	return nxt ? &nxt->work : NULL;
> }
> ```

Then the result is that the same request appears two times in `__io_submit_flush_completions`

BTW, for io-wq, link advancing is done in `io_wq_free_work()` or `io_queue_next()` from
`io_free_batch_list`, and it depends on where the refcount drops to zero in the
two code paths.

## understand rsrc_node(v6.13)

- cover registered file & fixed buffer

resource lifetime management(buffer register/unregister vs buffer use)


## understand io_uring buffers

### fixed buffer

- imported in ->prep()

- may be delayed to ->issue()

- managed by rsrc_node

- why can't be imported more than once in `io_uring/rw.c`?

### plain userspace buffer

- call io_import_iovec() directly in ->prep()

- why does vectored buffer have to be imported in the submission context?
-EFAULT is observed when importing uiov in io-wq context. But not observed
in case of io_uring_prep_read().

    EFAULT is returned from copy_iovec_from_user() <- iovec_from_user <-
    __import_iovec, and **copy_from_user()** can be only done in the submission
    conext

### selected buffer

- io_import_iovec() directly, called in ->issue() only

- how to cover sync between providing buffer & buffer use, buffer group

- rsrc_node isn't used


### io_read() & io_write buffer use


### net io buffer use


## Add support for vectored registered buffers

[https://lore.kernel.org/all/cover.1741014186.git.asml.silence@gmail.com/#r](https://lore.kernel.org/all/cover.1741014186.git.asml.silence@gmail.com/#r)


# **how to support kernel buffer**

## motivation

- device zero copy

buffer is from kernel, and need to lease to io_uring for reading data to
the buffer, or writing data in the buffer.

It is like traditional copy_file_range() or splice() which can't support
to read data to the pages in pipe, also buffer ownership model isn't same.

[io_uring: support leased group buffer with REQ_F_GROUP_KBUF](https://lore.kernel.org/linux-block/20241025122247.3709133-6-ming.lei@redhat.com/)

> ```
> This way looks a bit similar with kernel's pipe/splice, but there are some
> important differences:
> 
> - splice is for transferring data between two FDs via pipe, and fd_out can
> only read data from pipe, but data can't be written to; this feature can
> lease buffer from group leader(driver subsystem) to members(io_uring subsystem),
> so member request can write data to this buffer if the buffer direction is
> allowed to write to.
> 
> - splice implements data transfer by moving pages between subsystem and
> pipe, that means page ownership is transferred, and this way is one of the
> most complicated thing of splice; this patch supports scenarios in which
> the buffer can't be transferred, and buffer is only borrowed to member
> requests for consumption, and is returned back after member requests
> consume the leased buffer, so buffer lifetime is aligned with group leader
> lifetime, and buffer lifetime is simplified a lot. Especially the buffer
> is guaranteed to be returned back.
> 
> - splice can't run in async way basically
> ```

Also it has to be careful for dealing with reading data to the kernel buffer.
If the kernel buffer may be copied to userspace, the application has to be
trusted, that said the application has to read data to the buffer, otherwise
kernel data may be leaked to userspace.

## design

### does it need to cover userspace buffer?

- such as, the buffer is originated from userspace, and it is provided
from one bpf OP(group leader)

- technically it is pretty easy to cover it

- at least it can be used for test purpose


## questions

### is faulted page for READ initialized as 0 before reading file data?



# **idea: buffer abstraction & generic buffer**

## use cases 
- one typical use case is for supporting io_uring bpf

io_uring exports kfunc for bpf prog, and buffer consumer is done as plugin,
which need to decouple OP implementation from buffer use

## buffer operations

- setup

- teardown

- import

- recycle(?)

