---
title: UIO
category: tech
tags: [userspace, driver, uio, vfio, linux kernel]
---

title: UIO

* TOC
{:toc}



# VFIO Complete Walkthrough

Generated by AI

This document provides a complete walkthrough of VFIO (Virtual Function I/O) with practical examples.

## Table of Contents
1. [What is VFIO?](#what-is-vfio)
2. [Prerequisites](#prerequisites)
3. [Architecture Overview](#architecture-overview)
4. [VFIO DMA Mapping and IOMMU Implementation](#vfio-dma-mapping-and-iommu-implementation)
5. [Step-by-Step Setup](#step-by-step-setup)
6. [Real-World Use Cases](#real-world-use-cases)
7. [Troubleshooting](#troubleshooting)

## What is VFIO?

**VFIO (Virtual Function I/O)** is a kernel framework that enables **safe, direct device access from userspace** using the IOMMU for memory protection.

### Key Benefits

- **Security**: IOMMU prevents malicious DMA attacks
- **Performance**: Direct hardware access, no kernel overhead
- **Flexibility**: Write drivers in userspace
- **Isolation**: Safe device sharing between VMs

### Primary Use Cases

1. **GPU Passthrough**: Gaming VMs with native graphics performance
2. **Network I/O**: DPDK for high-performance packet processing
3. **VM Device Assignment**: PCI device passthrough to KVM guests
4. **Userspace Drivers**: Custom hardware without kernel modules

## Prerequisites

### 1. Hardware Requirements

#### IOMMU Support
```bash
# Intel VT-d
grep -e DMAR -e IOMMU /var/log/dmesg

# AMD-Vi
grep -i iommu /var/log/dmesg

# ARM SMMU
dmesg | grep -i smmu
```

### 2. BIOS/UEFI Settings

Enable:
- **Intel VT-d** (Intel) or **AMD-Vi** (AMD)
- **Virtualization Technology**
- **IOMMU**

### 3. Kernel Boot Parameters

Add to kernel command line (`/etc/default/grub`):

```bash
# Intel
GRUB_CMDLINE_LINUX="intel_iommu=on iommu=pt"

# AMD
GRUB_CMDLINE_LINUX="amd_iommu=on iommu=pt"

# Then update grub
sudo grub2-mkconfig -o /boot/grub2/grub.cfg
sudo reboot
```

**Parameters explained:**
- `intel_iommu=on` / `amd_iommu=on`: Enable IOMMU
- `iommu=pt`: Passthrough mode (better performance for host devices)

### 4. Verify IOMMU is Active

```bash
# Check if IOMMU is enabled
dmesg | grep -i iommu

# Should see lines like:
# DMAR: Intel(R) Virtualization Technology for Directed I/O
# DMAR: IOMMU enabled
```

### 5. Required Kernel Modules

```bash
# Load VFIO modules
sudo modprobe vfio
sudo modprobe vfio-pci
sudo modprobe vfio_iommu_type1

# Verify
lsmod | grep vfio
```

## Architecture Overview

### The VFIO Stack

```
┌─────────────────────────────────────────────────┐
│                 Userspace                       │
│                                                 │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐     │
│  │   QEMU   │  │   DPDK   │  │  Custom  │     │
│  │  /KVM    │  │          │  │   App    │     │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘     │
│       │             │             │            │
│       └─────────────┴─────────────┘            │
│                     │                          │
│              /dev/vfio/vfio                    │
│              /dev/vfio/<group>                 │
└─────────────────────┼──────────────────────────┘
                      │
        ══════════════════════════
               Kernel Space
        ══════════════════════════
                      │
┌─────────────────────┼──────────────────────────┐
│              VFIO Framework                    │
│  ┌──────────────────────────────────────┐     │
│  │  Container (IOMMU context)           │     │
│  │    - Manages address spaces          │     │
│  │    - DMA mapping/unmapping           │     │
│  └──────────────────────────────────────┘     │
│  ┌──────────────────────────────────────┐     │
│  │  Group (isolation boundary)          │     │
│  │    - Device enumeration              │     │
│  │    - IRQ management                  │     │
│  │    - MMIO region access              │     │
│  └──────────────────────────────────────┘     │
│  ┌──────────────────────────────────────┐     │
│  │  Bus Driver (vfio-pci, etc.)         │     │
│  │    - Device binding                  │     │
│  │    - Config space access             │     │
│  └──────────────────────────────────────┘     │
└─────────────────────┼──────────────────────────┘
                      │
┌─────────────────────┼──────────────────────────┐
│                  IOMMU                         │
│  ┌──────────────────────────────────────┐     │
│  │  Address Translation                 │     │
│  │    GPA (Guest) → HPA (Host)          │     │
│  │    or IOVA → Physical Address        │     │
│  │                                       │     │
│  │  DMA Isolation                       │     │
│  │    Enforces memory access controls   │     │
│  └──────────────────────────────────────┘     │
└─────────────────────┼──────────────────────────┘
                      │
              ┌───────┴────────┐
              │                │
         ┌────▼─────┐    ┌────▼─────┐
         │   NIC    │    │   GPU    │
         └──────────┘    └──────────┘
           Hardware         Hardware
```

### IOMMU Groups

**Critical Concept**: Devices in the same IOMMU group can DMA to each other, so they must be assigned together.

```bash
# View all IOMMU groups
for g in /sys/kernel/iommu_groups/*/devices/*; do
    echo "Group $(basename $(dirname $(dirname $g))): $(basename $g)"
done | sort -V

# Example output:
# Group 1: 0000:00:00.0  (Host bridge)
# Group 2: 0000:00:01.0  (PCI bridge)
# Group 3: 0000:01:00.0  (GPU)
# Group 4: 0000:02:00.0  (NIC)
# Group 4: 0000:02:00.1  (NIC) ← Same group!
```

**Important**: All devices in Group 4 must be assigned together!

## VFIO DMA Mapping and IOMMU Implementation

This section explains in detail how VFIO DMA mapping works and how the IOMMU provides memory protection and address translation.

### The Problem VFIO Solves

Consider a device performing DMA (Direct Memory Access):

```
Without IOMMU - DANGEROUS:
┌──────────────┐
│   Device     │
│   (DMA)      │
└──────┬───────┘
       │ Device can DMA to ANY physical address!
       │ e.g., DMA to 0x1000 → Physical address 0x1000
       ↓
┌─────────────────────────────────────────┐
│      Physical Memory                    │
│  0x0000: Kernel code                    │
│  0x1000: Kernel data     ← Can corrupt! │
│  0x2000: Process A                      │
│  0x3000: Process B                      │
└─────────────────────────────────────────┘

Userspace can program device to:
- Read kernel memory (security breach!)
- Overwrite kernel data (system crash!)
- Access other VMs' memory (VM escape!)
```

With IOMMU - SAFE:
```
┌──────────────┐
│   Device     │
│   (DMA)      │
└──────┬───────┘
       │ Device uses IOVA (I/O Virtual Address)
       │ e.g., DMA to 0x10000000
       ↓
┌──────────────────────────┐
│       IOMMU              │
│   (Hardware MMU)         │
│                          │
│  Translate & Check:      │
│  0x10000000 → 0x50000    │ ← Only if allowed!
│                          │
│  If not in page table:   │
│  → IOMMU fault!         │
└──────┬───────────────────┘
       │ Only allowed physical addresses
       ↓
┌─────────────────────────────────────────┐
│      Physical Memory                    │
│  0x0000: Kernel code                    │
│  0x1000: Kernel data                    │
│  0x2000: Process A                      │
│  0x3000: Process B                      │
│  0x50000: DMA buffer    ← Only here!    │
└─────────────────────────────────────────┘
```

### IOMMU Hardware Architecture

The IOMMU sits between devices and memory, similar to how the CPU's MMU sits between CPU and memory:

```
CPU Side:                    Device Side:
┌─────────┐                 ┌─────────┐
│   CPU   │                 │ Device  │
└────┬────┘                 └────┬────┘
     │ Virtual Address          │ IOVA (I/O Virtual Addr)
     ↓                          ↓
┌────────────┐            ┌──────────────┐
│  CPU MMU   │            │    IOMMU     │
│            │            │              │
│ Page       │            │ I/O Page     │
│ Tables     │            │ Tables       │
└────┬───────┘            └──────┬───────┘
     │ Physical                  │ Physical
     │ Address                   │ Address
     └───────────────┬───────────┘
                     ↓
          ┌──────────────────┐
          │ Physical Memory  │
          └──────────────────┘
```

### Intel VT-d IOMMU Implementation

Intel's VT-d (Virtualization Technology for Directed I/O) uses multi-level page tables:

```
Device BDF → Root Table → Context Table → Page Tables → Physical Memory
(Bus:Dev:Fn)

Example: Device 01:00.0 performing DMA

Step 1: Root Table Lookup
┌─────────────────────────────┐
│      Root Table Entry       │ ← Indexed by Bus# (01)
│  Points to Context Table    │
└────────────┬────────────────┘
             ↓
Step 2: Context Table Lookup
┌─────────────────────────────┐
│    Context Entry            │ ← Indexed by DevFn (00.0)
│  - Address Space Root (ASR) │ ← Points to page tables
│  - Domain ID                │
│  - Translation Type         │
└────────────┬────────────────┘
             ↓
Step 3: Multi-Level Page Table Walk
┌─────────────────────────────┐
│   Level 4 Page Table        │
└────────────┬────────────────┘
             ↓
┌─────────────────────────────┐
│   Level 3 Page Table        │
└────────────┬────────────────┘
             ↓
┌─────────────────────────────┐
│   Level 2 Page Table        │
└────────────┬────────────────┘
             ↓
┌─────────────────────────────┐
│   Level 1 Page Table (PTE)  │
│  - Physical Address         │
│  - Read/Write permissions   │
│  - Present bit              │
└────────────┬────────────────┘
             ↓
      Physical Memory
```

### VFIO Type1 IOMMU Driver

VFIO's Type1 IOMMU driver (`vfio_iommu_type1`) manages IOMMU page tables:

#### Key Data Structures

```c
/* Container - represents an IOMMU context */
struct vfio_iommu {
    struct list_head        domain_list;    /* List of IOMMU domains */
    struct mutex            lock;           /* Protects domain_list */
    struct rb_root          dma_list;       /* RB tree of DMA mappings */
    bool                    v2;             /* Type1 v2 extensions */
    bool                    nesting;        /* Nested translation */
};

/* IOMMU Domain - hardware page table context */
struct vfio_domain {
    struct iommu_domain     *domain;        /* Actual IOMMU domain */
    struct list_head        next;           /* Next in container */
    struct list_head        group_list;     /* Groups in this domain */
    bool                    fgsp;           /* Fine-grained super pages */
};

/* DMA Mapping - tracks each mapped region */
struct vfio_dma {
    struct rb_node          node;           /* RB tree node */
    dma_addr_t              iova;           /* I/O virtual address */
    unsigned long           vaddr;          /* Process virtual address */
    size_t                  size;           /* Mapping size */
    int                     prot;           /* IOMMU_READ | IOMMU_WRITE */
    struct task_struct      *task;          /* Task owning the memory */
    struct vfio_pfn_list    pfn_list;       /* Pinned pages */
};
```

### DMA Mapping Workflow

When userspace calls `VFIO_IOMMU_MAP_DMA`:

```c
/* Userspace API call */
struct vfio_iommu_type1_dma_map {
    __u32   argsz;
    __u32   flags;              /* VFIO_DMA_MAP_FLAG_READ | WRITE */
    __u64   vaddr;              /* Process virtual address */
    __u64   iova;               /* I/O virtual address (device sees this) */
    __u64   size;               /* Size of mapping */
};

ioctl(container_fd, VFIO_IOMMU_MAP_DMA, &dma_map);
```

#### Kernel Processing Steps:

```
1. Userspace Preparation
   ┌──────────────────────────┐
   │ Allocate buffer:         │
   │   void *buf = malloc()   │
   │   or mmap()              │
   └──────────┬───────────────┘
              ↓
2. Request DMA Mapping
   ┌──────────────────────────┐
   │ ioctl(VFIO_IOMMU_MAP_DMA)│
   │   vaddr = 0x7f0000000    │ ← Userspace VA
   │   iova  = 0x10000000     │ ← Device address
   │   size  = 4096           │
   └──────────┬───────────────┘
              ↓
3. Kernel: vfio_iommu_type1_ioctl()
   ┌──────────────────────────┐
   │ Validate parameters      │
   │ - Check alignment        │
   │ - Check overlaps         │
   │ - Verify user owns vaddr │
   └──────────┬───────────────┘
              ↓
4. Pin User Pages
   ┌──────────────────────────┐
   │ pin_user_pages_remote()  │
   │ - Walk page tables       │
   │ - Pin physical pages     │
   │ - Increment page refcount│
   │ - Prevent page from      │
   │   being swapped out      │
   └──────────┬───────────────┘
              ↓
5. Get Physical Addresses
   ┌──────────────────────────┐
   │ For each pinned page:    │
   │   pfn = page_to_pfn(page)│
   │   phys = pfn << PAGE_SHIFT│
   └──────────┬───────────────┘
              ↓
6. Program IOMMU Page Tables
   ┌──────────────────────────┐
   │ iommu_map()              │
   │   domain = vfio_domain   │
   │   iova = 0x10000000      │
   │   phys = 0x50000         │ ← Physical addr
   │   size = 4096            │
   │   prot = READ|WRITE      │
   │                          │
   │ This creates PTE:        │
   │   IOVA[0x10000000] →     │
   │     PA[0x50000]          │
   │     Permissions: RW      │
   │     Present: 1           │
   └──────────┬───────────────┘
              ↓
7. Flush IOMMU TLB
   ┌──────────────────────────┐
   │ iommu_flush_iotlb()      │
   │ - Clear cached entries   │
   │ - Ensure new mapping     │
   │   is visible to device   │
   └──────────┬───────────────┘
              ↓
8. Track Mapping
   ┌──────────────────────────┐
   │ vfio_dma_do_map()        │
   │ - Allocate vfio_dma      │
   │ - Insert into RB tree    │
   │ - Store pinned pages     │
   └──────────────────────────┘
```

### Complete Memory Flow Example

Let's trace a DMA operation from start to finish:

```
Scenario: Userspace wants device to DMA 4KB to a buffer

┌─────────────────────────────────────────────────────────────┐
│ 1. Userspace Allocates Buffer                              │
└─────────────────────────────────────────────────────────────┘

void *buffer = mmap(NULL, 4096, PROT_READ | PROT_WRITE,
                    MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);

// buffer = 0x7f1234000 (virtual address in process)

Process Address Space:
┌──────────────────────┐
│  ...                 │
│  0x7f1234000  ─┐     │
│  [4KB buffer]  │     │
│  0x7f1235000  ─┘     │
│  ...                 │
└──────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│ 2. Map for DMA                                              │
└─────────────────────────────────────────────────────────────┘

struct vfio_iommu_type1_dma_map dma_map = {
    .argsz = sizeof(dma_map),
    .vaddr = 0x7f1234000,     // Process virtual address
    .iova  = 0x20000000,      // Device virtual address
    .size  = 4096,
    .flags = VFIO_DMA_MAP_FLAG_READ | VFIO_DMA_MAP_FLAG_WRITE,
};

ioctl(container_fd, VFIO_IOMMU_MAP_DMA, &dma_map);

Kernel Action:
- Walks process page tables for 0x7f1234000
- Finds physical page at 0x50000
- Pins the page (prevents swapping)
- Programs IOMMU:

  IOMMU Page Table Entry:
  ┌────────────────────────────┐
  │ IOVA: 0x20000000           │
  │   ↓                        │
  │ Physical: 0x50000          │
  │ Permissions: RW            │
  │ Present: Yes               │
  └────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│ 3. Program Device                                           │
└─────────────────────────────────────────────────────────────┘

// Write to device registers via MMIO
volatile uint32_t *device_regs = mmap_device_bar0();

device_regs[DMA_ADDR_REG] = 0x20000000;  // IOVA!
device_regs[DMA_SIZE_REG] = 4096;
device_regs[DMA_CTRL_REG] = DMA_START | DMA_WRITE;

┌─────────────────────────────────────────────────────────────┐
│ 4. Device Performs DMA                                      │
└─────────────────────────────────────────────────────────────┘

Device generates DMA transaction:
  Address: 0x20000000 (IOVA)
  Size: 4096 bytes
  Data: [device data]

     │
     ↓
┌────────────────────────────────┐
│         IOMMU                  │
│                                │
│ 1. Receive DMA transaction     │
│    IOVA = 0x20000000           │
│                                │
│ 2. Look up in page tables:     │
│    Root table [Bus]            │
│      → Context [Dev:Fn]        │
│        → Page tables           │
│          → PTE                 │
│                                │
│ 3. Find mapping:               │
│    0x20000000 → 0x50000        │
│    Permissions: RW ✓           │
│                                │
│ 4. Check permissions:          │
│    Write requested? Yes        │
│    Write allowed? Yes ✓        │
│                                │
│ 5. Translate address:          │
│    Physical = 0x50000          │
│                                │
│ 6. Forward to memory:          │
│    Write 4KB to 0x50000        │
└────────┬───────────────────────┘
         │
         ↓
┌────────────────────────────────┐
│    Physical Memory             │
│                                │
│  0x50000: [DMA data written]   │ ← Success!
│                                │
└────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│ 5. Userspace Reads Result                                  │
└─────────────────────────────────────────────────────────────┘

// Wait for DMA complete interrupt
read(eventfd, &val, sizeof(val));

// Read data from buffer
memcpy(local_buf, buffer, 4096);

CPU Action:
- CPU accesses virtual address 0x7f1234000
- CPU MMU translates to physical 0x50000
- CPU reads data that device wrote

The data flows:
  Device → IOMMU(translate) → Physical Mem → CPU MMU → Process
```

### IOMMU Page Table Structure

For x86-64 with 4-level paging (similar to CPU page tables):

```
IOVA Breakdown (48-bit address):
┌──────┬──────┬──────┬──────┬────────────┐
│ L4   │ L3   │ L2   │ L1   │   Offset   │
│ 9bit │ 9bit │ 9bit │ 9bit │   12bit    │
└──────┴──────┴──────┴──────┴────────────┘
 47-39  38-30  29-21  20-12    11-0

Example IOVA = 0x20001234:
  0x00 0000 2000 1234

  Bits 47-39 (L4): 0x000 = entry 0
  Bits 38-30 (L3): 0x000 = entry 0
  Bits 29-21 (L2): 0x001 = entry 1
  Bits 20-12 (L1): 0x000 = entry 0
  Bits 11-0 (Off): 0x234 = byte offset

Page Table Walk:
┌───────────────────────────────┐
│ Context Entry (from dev)      │
│   ASR → Level 4 Table         │
└──────────┬────────────────────┘
           │
           ↓ Index [0]
┌───────────────────────────────┐
│ Level 4 Page Table            │
│ Entry[0] → Level 3 Table      │
└──────────┬────────────────────┘
           │
           ↓ Index [0]
┌───────────────────────────────┐
│ Level 3 Page Table            │
│ Entry[0] → Level 2 Table      │
└──────────┬────────────────────┘
           │
           ↓ Index [1]
┌───────────────────────────────┐
│ Level 2 Page Table            │
│ Entry[1] → Level 1 Table      │
└──────────┬────────────────────┘
           │
           ↓ Index [0]
┌───────────────────────────────┐
│ Level 1 Page Table (PTE)      │
│ Entry[0]:                     │
│   Physical Address: 0x50000   │
│   Present:     1               │
│   Read:        1               │
│   Write:       1               │
│   Execute:     0               │
│   Snoop:       1 (cache coh.)  │
└──────────┬────────────────────┘
           │
           ↓ Add offset 0x234
┌───────────────────────────────┐
│ Physical Address: 0x50234     │
└───────────────────────────────┘
```

### IOMMU Fault Handling

If a device tries to access an unmapped or unauthorized address:

```
Device attempts DMA to 0x99999000 (not mapped)

     ↓
┌────────────────────────────────┐
│         IOMMU                  │
│                                │
│ 1. Look up 0x99999000          │
│    → Page table walk           │
│    → No valid PTE found        │
│                                │
│ 2. Generate IOMMU Fault        │
│    - Fault address: 0x99999000 │
│    - Fault reason: NOT_PRESENT │
│    - Device: 01:00.0           │
│                                │
│ 3. Block the DMA transaction   │
│    ✗ Do NOT access memory      │
│                                │
│ 4. Log fault:                  │
│    dmesg: DMAR fault           │
│                                │
│ 5. Notify software (optional)  │
│    - Fault interrupt           │
│    - Fault event to VFIO       │
└────────────────────────────────┘
         │
         ↓
  DMA aborted
  Device may receive error response
```

### Huge Page Support

VFIO supports huge pages (2MB, 1GB) for better performance:

```
Without Huge Pages:
┌────────────────────────────────┐
│ 512 × 4KB pages = 2MB          │
│ Requires: 512 PTEs             │
│ IOMMU TLB: 512 entries needed  │
│ TLB misses: frequent           │
└────────────────────────────────┘

With 2MB Huge Page:
┌────────────────────────────────┐
│ 1 × 2MB page = 2MB             │
│ Requires: 1 PTE                │
│ IOMMU TLB: 1 entry             │
│ TLB misses: rare               │
│ Performance: Much better       │
└────────────────────────────────┘

Code example:
// Allocate huge page
void *buf = mmap(NULL, 2*1024*1024,
                 PROT_READ | PROT_WRITE,
                 MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB,
                 -1, 0);

// VFIO will automatically use huge pages in IOMMU if possible
struct vfio_iommu_type1_dma_map dma_map = {
    .vaddr = (uint64_t)buf,
    .iova  = 0x20000000,
    .size  = 2*1024*1024,  // 2MB
    .flags = VFIO_DMA_MAP_FLAG_READ | VFIO_DMA_MAP_FLAG_WRITE,
};
```

### Kernel Code References

Key functions in the VFIO Type1 IOMMU driver:

```c
/* drivers/vfio/vfio_iommu_type1.c */

// Main ioctl handler
static long vfio_iommu_type1_ioctl(void *iommu_data,
                                    unsigned int cmd, unsigned long arg)

// Map DMA region
static int vfio_dma_do_map(struct vfio_iommu *iommu,
                           struct vfio_iommu_type1_dma_map *map)
{
    // 1. Validate IOVA range
    // 2. Pin user pages
    // 3. Create IOMMU mappings
    // 4. Track in vfio_dma structure
}

// Unmap DMA region
static int vfio_dma_do_unmap(struct vfio_iommu *iommu,
                             struct vfio_iommu_type1_dma_unmap *unmap)
{
    // 1. Find vfio_dma entries
    // 2. Remove IOMMU mappings
    // 3. Unpin pages
    // 4. Free vfio_dma structures
}

// Pin user memory pages
static long vfio_pin_pages_remote(struct vfio_dma *dma,
                                   unsigned long vaddr,
                                   long npage,
                                   unsigned long *pfn_base)
{
    // Use pin_user_pages_remote() to:
    // - Walk page tables
    // - Pin physical pages
    // - Return PFNs
}

// Actual IOMMU mapping
static int vfio_iommu_map(struct vfio_iommu *iommu,
                          dma_addr_t iova,
                          unsigned long pfn,
                          long npage, int prot)
{
    list_for_each_entry(d, &iommu->domain_list, next) {
        ret = iommu_map(d->domain, iova, (phys_addr_t)pfn << PAGE_SHIFT,
                        npage << PAGE_SHIFT, prot | d->prot);
    }
}
```

### DMA Coherency and Cache Management

IOMMU ensures DMA coherency with CPU caches:

```
Without Snoop Control:
┌─────────┐                 ┌─────────┐
│   CPU   │                 │ Device  │
│  Cache  │                 │  DMA    │
└────┬────┘                 └────┬────┘
     │                           │
     │ Cached data              │ Writes directly
     │ (stale!)                 │ to memory
     ↓                           ↓
┌──────────────────────────────────┐
│         Memory                   │
│  CPU sees old cached value       │
│  Device wrote new value          │
│  → INCONSISTENCY!                │
└──────────────────────────────────┘

With IOMMU Snoop:
┌─────────┐                 ┌─────────┐
│   CPU   │                 │ Device  │
│  Cache  │←──────Snoop─────│  DMA    │
└────┬────┘     coherency   └────┬────┘
     │             ↑             │
     │             │             │
     │        ┌────┴────┐        │
     └────────│  IOMMU  │────────┘
              │ Enforces│
              │ Snoop   │
              └────┬────┘
                   ↓
           ┌──────────────┐
           │    Memory    │
           │  Always      │
           │  Consistent  │
           └──────────────┘
```

### Performance Considerations

```
1. TLB Misses
   - IOMMU has a TLB (IOTLB) like CPU
   - Misses cause page table walks (expensive)
   - Solution: Use huge pages

2. Map/Unmap Overhead
   - Each map requires page table updates
   - TLB flushes are expensive
   - Solution: Map once, reuse mapping

3. Page Pinning
   - Pinned pages can't be swapped
   - Limits available memory
   - Solution: Unpin when not in use

4. Interrupt Remapping
   - IOMMU also remaps MSI interrupts
   - Adds latency to interrupt delivery
   - Solution: Use posted interrupts (VT-d PI)

Benchmark example:
┌──────────────────────────┬───────────┬────────────┐
│ Operation                │ Latency   │ Throughput │
├──────────────────────────┼───────────┼────────────┤
│ DMA Map (4KB)            │ ~10 µs    │ 100K ops/s │
│ DMA Map (2MB huge)       │ ~10 µs    │ 100K ops/s │
│ DMA Unmap (4KB)          │ ~8 µs     │ 125K ops/s │
│ DMA transaction (mapped) │ +50 ns    │ Same as    │
│   vs. no IOMMU          │           │ no IOMMU   │
│ IOTLB miss penalty       │ ~200 ns   │ N/A        │
└──────────────────────────┴───────────┴────────────┘
```

### Summary

VFIO DMA mapping provides:

1. **Security**: IOMMU prevents unauthorized memory access
2. **Address Translation**: Maps process virtual → device virtual (IOVA) → physical
3. **Memory Pinning**: Keeps pages in physical memory (no swapping)
4. **Cache Coherency**: Ensures CPU and device see consistent data
5. **Fault Isolation**: Faults are contained, don't crash system

The key insight is that the IOMMU provides a **per-device MMU**, giving each device its own isolated address space - just like processes have isolated virtual memory thanks to the CPU's MMU.

## Step-by-Step Setup

### Step 1: Identify Your Device

```bash
# List all PCI devices
lspci

# Find your target device (example: NIC)
lspci | grep -i ethernet

# Get detailed info
lspci -vvv -s 0000:02:00.0
```

### Step 2: Check IOMMU Group

```bash
# Using our helper script
./vfio_bind_device.sh 0000:02:00.0 status

# Manual check
ls -l /sys/bus/pci/devices/0000:02:00.0/iommu_group
```

### Step 3: Bind Device to vfio-pci

```bash
# Option 1: Use helper script
sudo ./vfio_bind_device.sh 0000:02:00.0 bind

# Option 2: Manual binding
# a) Find vendor:device ID
VENDOR=$(cat /sys/bus/pci/devices/0000:02:00.0/vendor)
DEVICE=$(cat /sys/bus/pci/devices/0000:02:00.0/device)

# b) Unbind from current driver (if bound)
echo "0000:02:00.0" | sudo tee /sys/bus/pci/devices/0000:02:00.0/driver/unbind

# c) Load vfio-pci
sudo modprobe vfio-pci

# d) Bind to vfio-pci
echo "$VENDOR $DEVICE" | sudo tee /sys/bus/pci/drivers/vfio-pci/new_id
```

### Step 4: Verify VFIO Device

```bash
# Check IOMMU group
ls -l /sys/bus/pci/devices/0000:02:00.0/iommu_group
# Should show: ../../kernel/iommu_groups/X

# Check vfio device node exists
ls -l /dev/vfio/X  # X is the group number

# Verify driver binding
cat /sys/bus/pci/devices/0000:02:00.0/driver
# Should show: ../../../bus/pci/drivers/vfio-pci
```

### Step 5: Use the Device

```bash
# Compile the example
gcc -o vfio_example vfio_simple_example.c

# Run it
sudo ./vfio_example 0000:02:00.0
```

## Real-World Use Cases

### Use Case 1: GPU Passthrough to VM

**Scenario**: Pass a dedicated GPU to a Windows VM for gaming.

```xml
<!-- QEMU/KVM libvirt configuration snippet -->
<hostdev mode='subsystem' type='pci' managed='yes'>
  <source>
    <address domain='0x0000' bus='0x01' slot='0x00' function='0x0'/>
  </source>
  <address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x0'/>
</hostdev>
```

**How it works**:
1. Host binds GPU to vfio-pci
2. QEMU opens VFIO device
3. QEMU creates VM with IOMMU mapping
4. Guest sees real GPU hardware
5. Guest loads native GPU drivers
6. Near-native performance!

**Benefits**:
- ~95% native performance
- Full driver support in guest
- Multiple VMs can have different GPUs

### Use Case 2: DPDK High-Performance Networking

**Scenario**: Userspace network packet processing at 10+ Gbps.

```c
/* DPDK pseudo-code */
int main() {
    /* DPDK internally uses VFIO */
    rte_eal_init(argc, argv);

    /* Get NIC port (bound to vfio-pci) */
    uint16_t port = 0;

    /* Configure with zero-copy DMA */
    rte_eth_dev_configure(port, ...);

    /* Receive packets directly via VFIO DMA */
    while (1) {
        struct rte_mbuf *pkts[32];
        nb_rx = rte_eth_rx_burst(port, 0, pkts, 32);

        /* Process packets in userspace */
        for (i = 0; i < nb_rx; i++)
            process_packet(pkts[i]);
    }
}
```

**Benefits**:
- Kernel bypass: no system calls
- Zero-copy: DMA directly to userspace
- Better latency: microseconds vs milliseconds
- Higher throughput: 10-100 Gbps possible

### Use Case 3: Custom Hardware Device

**Scenario**: Access custom FPGA or hardware accelerator from userspace.

```c
/* Simple MMIO access */
int main() {
    int device_fd = setup_vfio("0000:04:00.0");

    /* Map BAR0 (device MMIO registers) */
    void *bar0 = mmap(NULL, BAR0_SIZE,
                      PROT_READ | PROT_WRITE,
                      MAP_SHARED, device_fd, BAR0_OFFSET);

    /* Write to device register */
    volatile uint32_t *reg = (uint32_t *)bar0;
    reg[0] = 0x12345678;  /* Write command */

    /* Read status */
    uint32_t status = reg[1];

    /* Setup DMA buffer */
    void *dma_buf = alloc_dma_buffer(container_fd, 1024*1024);

    /* Tell device to DMA */
    reg[2] = get_iova(dma_buf);  /* DMA address */
    reg[3] = 1024*1024;          /* Size */
    reg[0] = CMD_START_DMA;      /* Start */

    /* Wait for completion */
    while (!(reg[1] & STATUS_DMA_DONE));

    /* Process data in dma_buf */
}
```

**Benefits**:
- Rapid prototyping
- Easy debugging (userspace tools)
- No kernel module needed
- Safe DMA via IOMMU

## Troubleshooting

### Problem: "IOMMU not found"

```bash
# Check IOMMU in BIOS - must be enabled!

# Verify kernel parameters
cat /proc/cmdline | grep iommu

# Check dmesg
dmesg | grep -i iommu
# Should see: "IOMMU enabled" or similar
```

**Solution**: Enable VT-d/AMD-Vi in BIOS, add kernel parameters, reboot.

### Problem: "Group not viable"

```bash
# Check group devices
ls -l /sys/kernel/iommu_groups/X/devices/

# Find which device is not bound to vfio
for dev in /sys/kernel/iommu_groups/X/devices/*; do
    echo "$(basename $dev): $(readlink $dev/driver 2>/dev/null || echo 'no driver')"
done
```

**Solution**: Bind ALL devices in the group to vfio-pci or unbind them.

### Problem: "Operation not permitted"

**Causes**:
1. Not running as root
2. SELinux blocking
3. Secure boot enabled
4. Device in use by another driver

```bash
# Run as root
sudo ./vfio_example ...

# Check SELinux
getenforce
sudo setenforce 0  # Temporary

# Check device usage
lsof | grep vfio
```

### Problem: Poor VM Performance

**Possible issues**:
1. CPU pinning not configured
2. Huge pages not enabled
3. IOMMU in strict mode (not passthrough)

```bash
# Enable huge pages
echo 1024 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages

# Use iommu=pt for better performance
# Edit /etc/default/grub, add: iommu=pt
```

### Problem: Device Reset Failed

Some devices don't support FLR (Function Level Reset).

```bash
# Check if reset is supported
cat /sys/bus/pci/devices/0000:XX:XX.X/reset

# Workaround: Use vendor-specific reset or reboot
```

## Advanced Topics

### Multiple Containers for Device Isolation

```c
/* Create separate containers for isolation */
int container1 = open("/dev/vfio/vfio", O_RDWR);
int container2 = open("/dev/vfio/vfio", O_RDWR);

/* Attach different groups */
attach_group(container1, group_id_1);
attach_group(container2, group_id_2);

/* Now devices can't DMA to each other */
```

### IRQ Handling with eventfd

```c
/* Setup MSI-X interrupt */
int eventfd = eventfd(0, 0);

struct vfio_irq_set irq_set = {
    .argsz = sizeof(irq_set) + sizeof(int),
    .flags = VFIO_IRQ_SET_DATA_EVENTFD | VFIO_IRQ_SET_ACTION_TRIGGER,
    .index = VFIO_PCI_MSIX_IRQ_INDEX,
    .start = 0,
    .count = 1,
};

memcpy(&irq_set.data, &eventfd, sizeof(int));
ioctl(device_fd, VFIO_DEVICE_SET_IRQS, &irq_set);

/* Wait for interrupt */
uint64_t count;
read(eventfd, &count, sizeof(count));
printf("Interrupt received!\n");
```

### Zero-Copy DMA Example

```c
/* Allocate huge page for better performance */
void *buffer = mmap(NULL, 2*1024*1024,
                    PROT_READ | PROT_WRITE,
                    MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB,
                    -1, 0);

/* Map for device DMA */
struct vfio_iommu_type1_dma_map dma_map = {
    .argsz = sizeof(dma_map),
    .vaddr = (uint64_t)buffer,
    .iova = 0x20000000,  /* Device address */
    .size = 2*1024*1024,
    .flags = VFIO_DMA_MAP_FLAG_READ | VFIO_DMA_MAP_FLAG_WRITE,
};

ioctl(container_fd, VFIO_IOMMU_MAP_DMA, &dma_map);

/* Device DMAs directly to userspace buffer! */
/* No copying, kernel just sets up IOMMU page tables */
```

## References

### Kernel Documentation
- `Documentation/driver-api/vfio.rst`
- `Documentation/virt/kvm/devices/vfio.rst`

### Headers
- `include/uapi/linux/vfio.h` - VFIO API definitions
- `include/linux/iommu.h` - IOMMU interface

### Related Projects
- **QEMU**: Uses VFIO for device passthrough
- **DPDK**: High-performance packet processing
- **SPDK**: Storage Performance Development Kit
- **libvirt**: VM management with VFIO devices

### Useful Commands

```bash
# List all IOMMU groups with devices
for d in /sys/kernel/iommu_groups/*/devices/*; do
    n=${d#*/iommu_groups/*}; n=${n%%/*}
    printf 'IOMMU Group %s ' "$n"
    lspci -nns "${d##*/}"
done

# Find devices suitable for passthrough (in singleton groups)
for g in /sys/kernel/iommu_groups/*; do
    if [ $(ls "$g/devices" | wc -l) -eq 1 ]; then
        echo "Singleton group $(basename $g): $(ls $g/devices)"
    fi
done

# Check device capabilities
lspci -vvv -s 0000:XX:XX.X | grep -i "capabilities\|reset"
```

## Summary

VFIO enables safe, high-performance device access from userspace by:

1. **Using IOMMU** for DMA protection and address translation
2. **Organizing devices** into isolation groups
3. **Providing APIs** for device control, DMA mapping, and interrupts
4. **Enabling use cases** like VM device passthrough, DPDK, and userspace drivers

The key insight is that the IOMMU acts as a "memory firewall" - it allows devices to perform DMA while preventing them from accessing unauthorized memory, making it safe to give userspace programs direct device access.


# DMA-BUF

## WALKTHROUGH

```
  1. The Cast of Characters

  In any DMA-BUF transaction, there are three distinct roles:

   * The Exporter: The driver that allocates the memory and "owns" the backing storage. (e.g., A GPU driver allocating a texture, or
     a camera driver allocating a frame).
   * The Importer: The driver that wants to access that memory. (e.g., A Display driver wanting to show the texture, or in your
     patchset's case, the NVMe driver wanting to write it to disk).
   * Userspace: The coordinator. It doesn't touch the data; it just passes the "ticket" (file descriptor) from the Exporter to the
     Importer.

  2. The Lifecycle of a DMA-BUF

  Step 1: Exporting (Allocation)
  Everything starts in the Exporter driver.
   1. Userspace requests a buffer (e.g., via a GPU IOCTL like DRM_IOCTL_MODE_CREATE_DUMB).
   2. The driver allocates physical memory pages.
   3. The driver calls dma_buf_export(). This creates a new struct dma_buf kernel object.
       * This object contains ops (operations) like map_dma_buf, unmap_dma_buf, release, etc.
   4. The driver gives a File Descriptor (FD) representing this buffer back to userspace.

  Step 2: Handover
  Userspace holds the FD. It passes this FD to the Importer driver (e.g., via the io_uring registration in your patchset).

  Step 3: Attachment (dma_buf_attach)
  Before the Importer can use the memory, it must "attach" to the buffer.
   1. The Importer calls dma_buf_attach(dmabuf, device).
   2. The DMA-BUF subsystem creates a struct dma_buf_attachment.
   3. Negotiation: This step ensures the two devices are compatible. For example, the Exporter might check if the Importer is a peer
      device connected via PCIe P2P, or if the memory needs to be moved to a specific region for the Importer to reach it.

  Step 4: Mapping (dma_buf_map_attachment)
  This is the critical step for performance.
   1. When the Importer is ready to do I/O, it calls dma_buf_map_attachment().
   2. The Exporter's callback is triggered. Its job is to generate a Scatter-Gather Table (`sg_table`).
       * Why Scatter-Gather? In physical memory, the buffer might be fragmented (scattered). The sg_table is a list of physical
         address ranges and lengths.
   3. The Translation: The Exporter maps these physical pages into the Importer's DMA address space.
       * If an IOMMU is present, this creates IO-Virtual Addresses (IOVA) mapped to the physical pages.
   4. The Importer receives the sg_table containing valid DMA addresses it can program directly into its hardware.

  Step 5: Synchronization (Fences)
  Sharing memory is dangerous. What if the GPU is still writing to the buffer while the NVMe drive tries to read it?
   * DMA-BUF uses dma_fence objects associated with the dma_buf.
   * Implicit Synchronization: The kernel tracks fences automatically. If the Exporter attaches a "write fence," the Importer knows
     to wait until that fence is signaled before starting its DMA transfer.
   * Explicit Synchronization: Userspace manages the fences (sync objects) and tells the kernel exactly when to wait.

  Step 6: Detach and Release
   1. When the I/O is done, the Importer calls dma_buf_unmap_attachment() (unmapping the DMA addresses) and dma_buf_detach().
   2. When userspace closes the FD, dma_buf_put() is called. When the reference count hits zero, the Exporter frees the physical
      memory.

  ---

  3. Key Structures to Recognize

  If you look at the code (specifically include/linux/dma-buf.h), these are the structs you will see:

   * `struct dma_buf`: The central object representing the shared buffer. It holds the size, file pointer, and ops.
   * `struct dma_buf_ops`: The vtable implemented by the Exporter.
       * .attach: "Can this device access me?"
       * .map_dma_buf: "Give me the scatter-gather list for this device."
   * `struct dma_buf_attachment`: Represents the link between one Importer and the DMA-BUF. A single buffer can have multiple
     attachments (e.g., one buffer shared by GPU, Video Encoder, and Display).

  4. How the Patchset Uses This

  Relating this back to the io_uring patchset:

   1. Registration: When you register the dmabuf with io_uring, the kernel acts as the Importer. It calls dma_buf_attach.
   2. Submission: When you submit a write request, io_uring (via the block layer) calls dma_buf_map_attachment.
   3. Zero-Copy: The block layer gets the sg_table (DMA addresses) from the dmabuf and passes those addresses directly to the NVMe
      driver.
   4. No CPU Copy: The NVMe drive reads directly from the physical addresses provided by the Exporter (e.g., GPU memory), completely
      bypassing the CPU linear mapping.

```


# Related features

## Patchset "vfio/pci: Allow MMIO regions to be exported through dma-buf"

[[PATCH v6 00/11] vfio/pci: Allow MMIO regions to be exported through dma-buf](https://lore.kernel.org/linux-block/20251102-dmabuf-vfio-v6-0-d773cff0db9f@nvidia.com/)


# VFIO use case in SPDK

## VFIO Container Management

SPDK uses a global VFIO configuration structure (memory.c:38-54): 

```
struct vfio_cfg {
    int fd;                    // VFIO container file descriptor
    bool enabled;              // VFIO is active
    bool noiommu_enabled;      // No-IOMMU mode
    unsigned device_ref;       // Device reference count
    TAILQ_HEAD(, spdk_vfio_dma_map) maps;  // DMA mapping list
    pthread_mutex_t mutex;
};
```

## VFIO Initialization Flow

```
1. Detection (memory.c:1316-1366): SPDK discovers DPDK's VFIO container by scanning /proc/self/fd for 
symlinks to /dev/vfio/vfio 

2. Device Isolation (pci.c:1005-1056): Uses file locks at /var/tmp/spdk_pci_lock_<BDF> to prevent 
multiple processes from claiming the same device

3. Lazy Mapping: DMA mappings are tracked but deferred until the first device is attached, then 
applied via ioctl(VFIO_IOMMU_MAP_DMA)
```

## IOMMU Support

### Two IOVA Modes

```
SPDK supports two address translation modes:

1. RTE_IOVA_VA: Virtual addresses used as IOVA (requires IOMMU)

- Device uses virtual addresses as IOVAs
- Simpler for applications (no translation needed)
- Requires IOMMU hardware support
- Common in modern systems

2. RTE_IOVA_PA: Physical addresses used as IOVA

- Device uses physical addresses as IOVAs
- Legacy mode or when IOMMU unavailable
- Requires /proc/self/pagemap access

```

### DMA Mapping Process

When mapping BARs or registering DMA buffers (pci.c:742-777):

```
int spdk_pci_device_map_bar(struct spdk_pci_device *dev, uint32_t bar,
                             void **mapped_addr, uint64_t *phys_addr, uint64_t *size)
{
    rc = dev->map_bar(dev, bar, mapped_addr, phys_addr, size);

    if (spdk_iommu_is_enabled()) {
        if (rte_eal_iova_mode() == RTE_IOVA_VA) {
            // Use virtual address as IOVA
            rc = vtophys_iommu_map_dma_bar((uint64_t)(*mapped_addr),
                                           (uint64_t)*mapped_addr, *size);
            *phys_addr = (uint64_t)(*mapped_addr);
        } else {
            // Use physical address as IOVA
            rc = vtophys_iommu_map_dma_bar((uint64_t)(*mapped_addr),
                                           *phys_addr, *size);
        }
    }
}
```

The VFIO DMA mapping structure (memory.c:763-844):

```
struct spdk_vfio_dma_map {
    struct vfio_iommu_type1_dma_map map;  // Kernel VFIO structure
    // map contains:
    // - vaddr: virtual address
    // - iova: I/O virtual address (VA or PA depending on mode)
    // - size: mapping size
    // - flags: VFIO_DMA_MAP_FLAG_READ | VFIO_DMA_MAP_FLAG_WRITE
};
```

##  Complete Flow

###  Device Initialization

```
  1. Probe: nvme_pcie_ctrlr_construct() at nvme_pcie.c
  2. Claim: Acquire exclusive lock via spdk_pci_device_claim()
  3. Map BARs:
    - BAR0: MMIO registers → pctrlr->regs
    - Optional CMB (Controller Memory Buffer) for submission queues
    - Optional PMR (Persistent Memory Region)
  4. IOMMU mapping: Each BAR mapped via vtophys_iommu_map_dma_bar() → ioctl(VFIO_IOMMU_MAP_DMA)
```

### Queue Pair Setup (nvme_pcie_common.c:98-229)

```
// Submission Queue - may use CMB or host memory
if (ctrlr->opts.use_cmb_sqs) {
    pqpair->cmd = nvme_pcie_ctrlr_alloc_cmb(...);  // In device memory
    pqpair->sq_in_cmb = true;
} else {
    pqpair->cmd = spdk_zmalloc(...);  // In host memory
    pqpair->cmd_bus_addr = nvme_pcie_vtophys(ctrlr, pqpair->cmd, NULL);
}

// Completion Queue - always in host memory
pqpair->cpl = spdk_zmalloc(...);
pqpair->cpl_bus_addr = nvme_pcie_vtophys(ctrlr, pqpair->cpl, NULL);

// Doorbell registers - MMIO pointers
pqpair->sq_tdbl = doorbell_base + (2 * qpair->id + 0) * stride;
pqpair->cq_hdbl = doorbell_base + (2 * qpair->id + 1) * stride;
```

### I/O Submission

```
1. Build command: Create NVMe command with PRP (Physical Region Page) list
2. Address translation: Use nvme_pcie_vtophys() to convert buffer addresses to IOVAs
3. Submit: Write command to submission queue
4. Ring doorbell: MMIO write to sq_tdbl register
```


## Summary: Complete Flow Diagram

```
  Application Start
      |
      v
  [1] spdk_env_init()
      |
      +---> pci_env_init()
      |       |
      |       +---> dpdk_pci_init()  (DPDK initializes VFIO container)
      |       +---> Register PCI drivers
      |       +---> scan_pci_bus()
      |
      +---> mem_map_init()  (Create g_mem_reg_map)
      |
      +---> vtophys_init()
              |
              +---> vtophys_iommu_init()
              |       |
              |       +---> Scan /proc/self/fd to find VFIO container FD
              |       +---> Set g_vfio.enabled = true
              |
              +---> Create g_phys_ref_map (reference counting)
              +---> Create g_vtophys_map (VA→IOVA translation)

  [2] Device Probe (spdk_nvme_probe)
      |
      v
  nvme_pcie_ctrlr_construct()
      |
      +---> spdk_pci_device_claim()  (Exclusive lock)
      |
      +---> nvme_pcie_ctrlr_allocate_bars()
      |       |
      |       +---> spdk_pci_device_map_bar(BAR0)
      |       |       |
      |       |       +---> DPDK maps BAR via mmap()
      |       |       +---> If IOMMU enabled:
      |       |       |       |
      |       |       |       +---> vtophys_iommu_map_dma_bar()
      |       |       |               |
      |       |       |               +---> _vfio_iommu_map_dma()
      |       |       |                       |
      |       |       |                       +---> ioctl(VFIO_IOMMU_MAP_DMA)
      |       |       |
      |       |       +---> Return virtual address and IOVA
      |       |
      |       +---> nvme_pcie_ctrlr_map_cmb() (optional)
      |       +---> nvme_pcie_ctrlr_map_pmr() (optional)
      |
      +---> Enable PCI Bus Mastering
      |
      +---> nvme_pcie_ctrlr_construct_admin_qpair()
              |
              +---> nvme_pcie_qpair_construct()
                      |
                      +---> Allocate SQ (in CMB or host memory)
                      +---> nvme_pcie_vtophys(SQ) → pqpair->cmd_bus_addr
                      +---> Allocate CQ (in host memory)
                      +---> nvme_pcie_vtophys(CQ) → pqpair->cpl_bus_addr
                      +---> Setup doorbell pointers (MMIO)
                      +---> Allocate and initialize trackers

  [3] Enable Controller
      |
      v
  nvme_pcie_ctrlr_enable()
      |
      +---> Write ASQ = admin_qpair->cmd_bus_addr (IOVA of Admin SQ)
      +---> Write ACQ = admin_qpair->cpl_bus_addr (IOVA of Admin CQ)
      +---> Write AQA = queue sizes
      +---> Set CC.EN = 1

  [4] Create I/O Queue Pairs
      |
      v
  nvme_pcie_ctrlr_create_io_qpair()
      |
      +---> nvme_pcie_qpair_construct()
      |       |
      |       +---> Allocate SQ/CQ in host memory
      |       +---> Get IOVAs via nvme_pcie_vtophys()
      |
      +---> nvme_pcie_ctrlr_cmd_create_io_cq()
      |       |
      |       +---> Send admin command with CQ IOVA in PRP1
      |
      +---> nvme_pcie_ctrlr_cmd_create_io_sq()
              |
              +---> Send admin command with SQ IOVA in PRP1

  [5] I/O Submission
      |
      v
  spdk_nvme_ns_cmd_read/write()
      |
      v
  nvme_pcie_qpair_submit_request()
      |
      +---> Get free tracker from pqpair->free_tr
      +---> Build PRP/SGL list:
      |       |
      |       +---> nvme_pcie_prp_list_append()
      |               |
      |               +---> For each buffer segment:
      |                       |
      |                       +---> phys_addr = nvme_pcie_vtophys(virt_addr)
      |                       |       |
      |                       |       +---> spdk_vtophys(virt_addr)
      |                       |               |
      |                       |               +---> spdk_mem_map_translate(g_vtophys_map)
      |                       |                       |
      |                       |                       +---> Returns IOVA
      |                       |
      |                       +---> cmd.prp1 = phys_addr (first PRP)
      |                       +---> tr->u.prp[i] = phys_addr (subsequent PRPs)
      |
      +---> nvme_pcie_qpair_submit_tracker()
              |
              +---> Copy command to SQ
              +---> Increment sq_tail
              +---> nvme_pcie_qpair_ring_sq_doorbell()
                      |
                      +---> MMIO write to doorbell register

  [6] I/O Completion
      |
      v
  nvme_pcie_qpair_process_completions()
      |
      +---> Poll CQ for new completions
      +---> For each completion:
              |
              +---> Find tracker by CID
              +---> nvme_pcie_qpair_complete_tracker()
              |       |
              |       +---> Call completion callback
              |       +---> Free tracker back to free_tr list
              |
              +---> nvme_pcie_qpair_ring_cq_doorbell()
                      |
                      +---> MMIO write to CQ doorbell

```

##  Key Takeaways

```
1. SPDK doesn't manage VFIO container directly - it discovers and reuses DPDK's container 

2. Lazy mapping strategy - DMA regions are tracked immediately but VFIO ioctls are deferred 
until first device attachment 

3. Two IOVA modes: 
  - IOVA=VA: Virtual addresses used as IOVAs, simpler and faster 

  - IOVA=PA: Physical addresses from /proc/self/pagemap used as IOVAs 

4. Reference counting - Multiple mappings to the same IOVA are reference-counted to support shared memory 

5. BAR handling - PCI BARs get special treatment and separate IOMMU mappings 

6. Zero-copy architecture - Direct MMIO access and DMA without intermediate buffers 

7. Memory granularity - All operations are 2MB-aligned for hugepage compatibility 

8. Device isolation - File locks at /var/tmp/spdk_pci_lock_<BDF> prevent multi-process conflicts 
```

