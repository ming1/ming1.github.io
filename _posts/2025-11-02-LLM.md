---
title: Understanding LLM
category: tech
tags: [AI, LLM]
---

title: Understanding LLM

* TOC
{:toc}

# Overview

[大语言模型训练数据](https://arxiv.org/html/2411.07715v1)


# Introduction to LLM

[Large language model](https://en.wikipedia.org/wiki/Large_language_model)

## Definition

```
A large language model (LLM) is a language model trained with self-supervised
machine learning on a vast amount of text, designed for natural language processing
tasks, especially language generation.[1][2] The largest and most capable LLMs
are generative pre-trained transformers (GPTs) and provide the core capabilities
of chatbots such as ChatGPT, Gemini and Claude. LLMs can be fine-tuned for specific
tasks or guided by prompt engineering.[3] These models acquire predictive power
regarding syntax, semantics, and ontologies[4] inherent in human language corpora,
but they also inherit inaccuracies and biases present in the data they are trained on.[5]
```

```
They consist of billions to trillions of parameters and operate as general-purpose
sequence models, generating, summarizing, translating, and reasoning over text. LLMs
represent a significant new technology in their ability to generalize across tasks
with minimal task-specific supervision, enabling capabilities like conversational
agents, code generation, knowledge retrieval, and automated reasoning that previously
required bespoke systems.[6]
```

## A Comprehensive Overview of Large Language Models

[A Comprehensive Overview of Large Language Models](https://arxiv.org/html/2307.06435v9)



## StockBench: Can Llm Agents Trade Stocks Profitably In Real-world Markets?

[https://arxiv.org/html/2510.02209v1](https://arxiv.org/html/2510.02209v1)


## What is vLLM?

[What is vLLM?](https://www.redhat.com/en/topics/ai/what-is-vllm)

```
vLLM, which stands for virtual large language model, is a library of open source code
maintained by the vLLM community. It helps large language models (LLMs) perform
calculations more efficiently and at scale.

Specifically, vLLM is an inference server that speeds up the output of generative
AI applications by making better use of the GPU memory. 
```



